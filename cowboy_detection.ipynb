{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import ToTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "num_classes = 6\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "root_path = \"data/images\"\n",
    "ann_path = 'data/train.json'\n",
    "coco_det = datasets.CocoDetection(\n",
    "    root=root_path, annFile=ann_path, transform=ToTensor()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{87: 0, 131: 1, 318: 2, 588: 3, 1034: 4}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "#\n",
    "# labels = set()\n",
    "# for img, targets in tqdm(iter(coco_det)):\n",
    "#     for target in targets:\n",
    "#         labels.add(target['category_id'])\n",
    "# labels\n",
    "\n",
    "labels = {87, 131, 318, 588, 1034}\n",
    "labels = sorted(list(labels))\n",
    "label_idx = {l: i for i, l in enumerate(sorted(list(labels)))}\n",
    "label_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def collate_fn_coco(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    coco_det, batch_size=2, shuffle=True, num_workers=0, collate_fn=collate_fn_coco)\n",
    "# For Training\n",
    "images, targets = next(iter(data_loader))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 4569006, 'image_id': 5482560941588709616, 'freebase_id': '/m/017ftj', 'category_id': 1034, 'iscrowd': False, 'bbox': [442.24, 274.69, 154.88, 56.35], 'area': 8726.89}]\n",
      "[{'id': 6155903, 'image_id': 7471380254599643684, 'freebase_id': '/m/017ftj', 'category_id': 1034, 'iscrowd': False, 'bbox': [144.0, 264.32, 111.36, 52.48], 'area': 5844.17}]\n"
     ]
    }
   ],
   "source": [
    "# - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with\n",
    "#   ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.\n",
    "# - labels (Int64Tensor[N]): the class label for each ground-truth box\n",
    "# print(targets)\n",
    "\n",
    "\n",
    "def process_targets(targets):\n",
    "    out = []\n",
    "    for target in targets:\n",
    "        print(target)\n",
    "        boxes = []\n",
    "        for t in target:\n",
    "            x1, y1, w, h, = t['bbox']\n",
    "            boxes.append([x1, y1, x1 + w, y1 + h])\n",
    "        boxes = torch.tensor(boxes)\n",
    "        labels = torch.tensor([label_idx[t['category_id']] for t in target], dtype=torch.int64)\n",
    "        out.append({'boxes': boxes,\n",
    "                    'labels': labels})\n",
    "    return out\n",
    "\n",
    "\n",
    "targets = process_targets(targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'loss_classifier': tensor(2.0073, grad_fn=<NllLossBackward>),\n 'loss_box_reg': tensor(0.0119, grad_fn=<DivBackward0>),\n 'loss_objectness': tensor(0.0722, grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n 'loss_rpn_box_reg': tensor(0.0082, grad_fn=<DivBackward0>)}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images = list(image for image in images)\n",
    "# targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images, targets)  # Returns losses and detections\n",
    "output\n",
    "# For inference\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "# predictions = model(images)\n",
    "# predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}